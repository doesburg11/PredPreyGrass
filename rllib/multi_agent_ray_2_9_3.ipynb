{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48228240",
   "metadata": {},
   "source": [
    "An alternative and simplified PredPreyGrass environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af020371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ray==2.9.3 (from ray[rllib]==2.9.3)\n",
      "  Using cached ray-2.9.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click>=7.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (8.1.7)\n",
      "Requirement already satisfied: filelock in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (4.21.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (1.0.7)\n",
      "Requirement already satisfied: packaging in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (23.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (4.23.4)\n",
      "Requirement already satisfied: pyyaml in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (6.0.1)\n",
      "Requirement already satisfied: aiosignal in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (1.4.1)\n",
      "Requirement already satisfied: requests in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray==2.9.3->ray[rllib]==2.9.3) (2.31.0)\n",
      "Requirement already satisfied: pandas in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (2.1.4)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (15.0.0)\n",
      "Requirement already satisfied: fsspec in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (2023.12.2)\n",
      "Requirement already satisfied: dm-tree in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (0.1.8)\n",
      "Collecting gymnasium==0.28.1 (from ray[rllib]==2.9.3)\n",
      "  Using cached gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: lz4 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (4.3.3)\n",
      "Requirement already satisfied: scikit-image in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (0.22.0)\n",
      "Requirement already satisfied: scipy in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (1.11.4)\n",
      "Requirement already satisfied: typer in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (0.9.0)\n",
      "Requirement already satisfied: rich in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from ray[rllib]==2.9.3) (13.7.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib]==2.9.3) (1.26.4)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib]==2.9.3) (1.0.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib]==2.9.3) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib]==2.9.3) (4.10.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from gymnasium==0.28.1->ray[rllib]==2.9.3) (0.0.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from jsonschema->ray==2.9.3->ray[rllib]==2.9.3) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from jsonschema->ray==2.9.3->ray[rllib]==2.9.3) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from jsonschema->ray==2.9.3->ray[rllib]==2.9.3) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from jsonschema->ray==2.9.3->ray[rllib]==2.9.3) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from pandas->ray[rllib]==2.9.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from pandas->ray[rllib]==2.9.3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from pandas->ray[rllib]==2.9.3) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from requests->ray==2.9.3->ray[rllib]==2.9.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from requests->ray==2.9.3->ray[rllib]==2.9.3) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from requests->ray==2.9.3->ray[rllib]==2.9.3) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from requests->ray==2.9.3->ray[rllib]==2.9.3) (2023.11.17)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from rich->ray[rllib]==2.9.3) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from rich->ray[rllib]==2.9.3) (2.17.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from scikit-image->ray[rllib]==2.9.3) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from scikit-image->ray[rllib]==2.9.3) (10.1.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from scikit-image->ray[rllib]==2.9.3) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from scikit-image->ray[rllib]==2.9.3) (2024.2.12)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from scikit-image->ray[rllib]==2.9.3) (0.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->ray[rllib]==2.9.3) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/doesburg/Dropbox/03_marl_code/PredPreyGrass/.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->ray[rllib]==2.9.3) (1.16.0)\n",
      "Using cached ray-2.9.3-cp311-cp311-manylinux2014_x86_64.whl (65.4 MB)\n",
      "Using cached gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "Installing collected packages: gymnasium, ray\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 0.29.1\n",
      "    Uninstalling gymnasium-0.29.1:\n",
      "      Successfully uninstalled gymnasium-0.29.1\n",
      "  Attempting uninstall: ray\n",
      "    Found existing installation: ray 2.3.0\n",
      "    Uninstalling ray-2.3.0:\n",
      "      Successfully uninstalled ray-2.3.0\n",
      "Successfully installed gymnasium-0.28.1 ray-2.9.3\n"
     ]
    }
   ],
   "source": [
    "! pip install \"ray[rllib]\"==2.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6b7165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________\n",
      "|1.... |\n",
      "|....  |\n",
      "|.2..  |\n",
      "|...   |\n",
      "|      |\n",
      "|      |\n",
      "‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1=-3.0\n",
      "R2=-3.9 (1 collisions)\n",
      "Env timesteps=50/50\n"
     ]
    }
   ],
   "source": [
    "from multi_agent_env_ray_2_9_3 import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import time\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\n",
    "    .environment(env=MultiAgentArena)\n",
    "    .multi_agent(\n",
    "        policies=[\"policy1\", \"policy2\"],\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "obs, _ = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "    \n",
    "while not dones[\"__all__\"]:\n",
    "\n",
    "    action1 = algo.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "    action2 = algo.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
    "\n",
    "    obs, rewards, dones, _, infos = env.step({\"agent1\": action1, \"agent2\": action2})\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b1a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________\n",
      "|1.... |\n",
      "|....  |\n",
      "|.2..  |\n",
      "|...   |\n",
      "|      |\n",
      "|      |\n",
      "‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1=-3.0\n",
      "R2=-3.9 (1 collisions)\n",
      "Env timesteps=50/50\n"
     ]
    }
   ],
   "source": [
    "#registering the environment\n",
    "from multi_agent_env_ray_2_9_3 import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "import time\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return MultiAgentArena(config=env_config)  # return an env instance\n",
    "\n",
    "register_env(\"multi_agent_arena\", env_creator)\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0, log_level=\"ERROR\")\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\n",
    "    .environment(env=\"multi_agent_arena\",)\n",
    "    .multi_agent(\n",
    "        policies=[\"policy1\", \"policy2\"],\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "obs, _ = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "    \n",
    "while not dones[\"__all__\"]:\n",
    "\n",
    "    action1 = algo.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "    action2 = algo.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
    "\n",
    "    obs, rewards, dones, _, infos = env.step({\"agent1\": action1, \"agent2\": action2})\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a0427c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________\n",
      "|1.... |\n",
      "|....  |\n",
      "|.2..  |\n",
      "|...   |\n",
      "|      |\n",
      "|      |\n",
      "‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1=-3.0\n",
      "R2=-3.9 (1 collisions)\n",
      "Env timesteps=50/50\n"
     ]
    }
   ],
   "source": [
    "#define policies in dict with PolicySpec\n",
    "from multi_agent_env_ray_2_9_3 import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return MultiAgentArena(config=env_config)  # return an env instance\n",
    "\n",
    "register_env(\"multi_agent_arena\", env_creator)\n",
    "\n",
    "policies = { \"policy1\": PolicySpec(), \"policy2\": PolicySpec() }\n",
    "\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"multi_agent_arena\")\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=lambda agent_id, episode, worker, **kwargs: \"policy1\" if agent_id == \"agent1\" else \"policy2\"\n",
    "    )\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "obs, _ = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "    \n",
    "while not dones[\"__all__\"]:\n",
    "\n",
    "    action1 = algo.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "    action2 = algo.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
    "\n",
    "    obs, rewards, dones, _, infos = env.step({\"agent1\": action1, \"agent2\": action2})\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e61f222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________\n",
      "|1.... |\n",
      "|....  |\n",
      "|.2..  |\n",
      "|...   |\n",
      "|      |\n",
      "|      |\n",
      "‾‾‾‾‾‾‾‾\n",
      "\n",
      "R1=-3.0\n",
      "R2=-3.9 (1 collisions)\n",
      "Env timesteps=50/50\n"
     ]
    }
   ],
   "source": [
    "#define policymapping\n",
    "from multi_agent_env_ray_2_9_3 import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def env_creator(env_config):\n",
    "    return MultiAgentArena(config=env_config)  # return an env instance\n",
    "\n",
    "register_env(\"multi_agent_arena\", env_creator)\n",
    "\n",
    "policies = { \"policy1\": PolicySpec(), \"policy2\": PolicySpec() }\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    \"\"\"\n",
    "    is exactly the same as:\n",
    "    policy_mapping_fn=  lambda agent_id, episode, worker, **kwargs: \"policy1\" \n",
    "                        if agent_id == \"agent1\" else \"policy2\"\n",
    "    \"\"\"\n",
    "    if agent_id == \"agent1\":\n",
    "        return \"policy1\"\n",
    "    else:\n",
    "        return \"policy2\"\n",
    "\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"multi_agent_arena\")\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "env = MultiAgentArena(config={\"render\": True})\n",
    "obs, _ = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "    \n",
    "while not dones[\"__all__\"]:\n",
    "\n",
    "    action1 = algo.compute_single_action(obs[\"agent1\"], policy_id=\"policy1\")\n",
    "    action2 = algo.compute_single_action(obs[\"agent2\"], policy_id=\"policy2\")\n",
    "\n",
    "    obs, rewards, dones, _, infos = env.step({\"agent1\": action1, \"agent2\": action2})\n",
    "\n",
    "    env.render()\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "algo.stop()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
