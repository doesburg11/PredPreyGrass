{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48228240",
   "metadata": {},
   "source": [
    "### An attempt to integrate PredPreyGrassEnv into ray rllib 2.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0a11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER I\n",
    "#define policies in dict with PolicySpec\n",
    "#add width and height parameters to the environment\n",
    "\n",
    "from environments.predpreygrass_env import PredPreyGrassEnv\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.pre_checks.env import  check_env\n",
    "from config.config_rllib import configuration\n",
    "import time\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "\n",
    "check_env(PredPreyGrassEnv(configuration))\n",
    "\n",
    "env = PredPreyGrassEnv(configuration=configuration)\n",
    "\n",
    "policy1 = PolicySpec(None,observation_space=env.observation_space, action_space=env.action_space)\n",
    "policy2 = PolicySpec(None,observation_space=env.observation_space, action_space=env.action_space)\n",
    "\n",
    "policies = { \n",
    "    \"policy1\": policy1,\n",
    "    \"policy2\": policy2\n",
    "}\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id.lower().startswith(\"predator\"):\n",
    "        return \"policy1\"\n",
    "    if agent_id.lower().startswith(\"prey\"):\n",
    "        return \"policy2\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected agent ID: {agent_id}\")\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=PredPreyGrassEnv,env_config=configuration)\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\n",
    "        \"fcnet_hiddens\" : [64, 64], \n",
    "        \"_disable_preprocessor_api\": False,\n",
    "        \"conv_filters\": [[32, [8, 8], 4], [64, [4, 4], 2], [512, [1, 1], 1]] # Copilot\n",
    "        }\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    ")\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "\n",
    "env = PredPreyGrassEnv(configuration=configuration)\n",
    "obs, _ = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "\n",
    "#print(obs)\n",
    "    \n",
    "algo.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8523e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER II\n",
    "#define policies in dict with PolicySpec\n",
    "#add width and height parameters to the environment\n",
    "\n",
    "from environments.predpreygrass_env import PredPreyGrassEnv\n",
    "from config.config_rllib import configuration\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.pre_checks.env import  check_env\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "env_config = {\n",
    "    \"no_done_at_end\": True,\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"num_workers\": 0   \n",
    "    }\n",
    "\n",
    "check_env(PredPreyGrassEnv(configuration))\n",
    "\n",
    "env = PredPreyGrassEnv(configuration=configuration)\n",
    "\n",
    "#policy1 = PolicySpec(None,observation_space=env.observation_space, action_space=env.action_space)\n",
    "#policy2 = PolicySpec(None,observation_space=env.observation_space, action_space=env.action_space)\n",
    "\n",
    "\n",
    "policy1 = PolicySpec()\n",
    "policy2 = PolicySpec()\n",
    "\n",
    "policies = { \n",
    "    \"policy1\": policy1,\n",
    "    \"policy2\": policy2\n",
    "}\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id.lower().startswith(\"predator\"):\n",
    "        return \"policy1\"\n",
    "    if agent_id.lower().startswith(\"prey\"):\n",
    "        return \"policy2\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected agent ID: {agent_id}\")\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=PredPreyGrassEnv, env_config=env_config)\n",
    "    .framework(\"torch\")\n",
    "    .experimental(_enable_new_api_stack=False)\n",
    "    .rollouts(\n",
    "        create_env_on_local_worker=True,\n",
    "        batch_mode=\"complete_episodes\", \n",
    "        num_rollout_workers=0\n",
    "    )\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\n",
    "        \"fcnet_hiddens\" : [64, 64], \n",
    "        \"_disable_preprocessor_api\": False,\n",
    "        \"conv_filters\": [[32, [8, 8], 4], [64, [4, 4], 2], [512, [1, 1], 1]] # Copilot\n",
    "        }\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    "    #.build()\n",
    ")\n",
    "\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "obs, _ = env.reset()\n",
    "dones = {\"__all__\" : False}\n",
    "\n",
    "#print(obs)\n",
    "\n",
    "action0 = algo.compute_single_action(obs[\"predator_0\"], policy_id=\"policy1\")\n",
    "action1 = algo.compute_single_action(obs[\"predator_1\"], policy_id=\"policy1\")\n",
    "action2 = algo.compute_single_action(obs[\"predator_2\"], policy_id=\"policy1\")\n",
    "action3 = algo.compute_single_action(obs[\"prey_3\"], policy_id=\"policy2\")\n",
    "action4 = algo.compute_single_action(obs[\"prey_4\"], policy_id=\"policy2\")\n",
    "action5 = algo.compute_single_action(obs[\"prey_5\"], policy_id=\"policy2\")\n",
    "print(\"action0\",action0)\n",
    "print(\"action1\",action1)\n",
    "print(\"action2\",action2)\n",
    "print(\"action3\",action3)\n",
    "print(\"action4\",action4)\n",
    "print(\"action5\",action5)\n",
    "\n",
    "algo.train()\n",
    "\n",
    "\n",
    "algo.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53e43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER III\n",
    "#define policies in dict with PolicySpec\n",
    "#add width and height parameters to the environment\n",
    "\n",
    "from environments.predpreygrass_env import PredPreyGrassEnv\n",
    "from config.config_rllib import configuration\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.pre_checks.env import  check_env\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "env_config = {\n",
    "    \"no_done_at_end\": True,\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"num_workers\": 0   \n",
    "    }\n",
    "\n",
    "check_env(PredPreyGrassEnv(configuration))\n",
    "\n",
    "def env_creator(configuration):\n",
    "    return PredPreyGrassEnv(configuration)  # return an env instance\n",
    "\n",
    "register_env(\"pred_prey_grass\", env_creator)\n",
    "\n",
    "policy1 = PolicySpec()\n",
    "policy2 = PolicySpec()\n",
    "\n",
    "policies = { \n",
    "    \"policy1\": policy1,\n",
    "    \"policy2\": policy2\n",
    "}\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id.startswith(\"predator_\"):\n",
    "        return \"policy1\"\n",
    "    if agent_id.startswith(\"prey_\"):\n",
    "        return \"policy2\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected agent ID: {agent_id}\")\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"pred_prey_grass\", env_config=env_config)\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(\n",
    "        create_env_on_local_worker=True,\n",
    "        batch_mode=\"complete_episodes\", \n",
    "        num_rollout_workers=0\n",
    "    )\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\n",
    "        \"fcnet_hiddens\" : [64, 64], \n",
    "        \"_disable_preprocessor_api\": False,\n",
    "        \"conv_filters\": [[32, [8, 8], 4], [64, [4, 4], 2], [512, [1, 1], 1]] # Copilot\n",
    "        }\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    "    #.build()\n",
    ")\n",
    "\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "env = PredPreyGrassEnv(configuration=configuration)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "#print(obs)\n",
    "\n",
    "action0 = algo.compute_single_action(obs[\"predator_0\"], policy_id=\"policy1\")\n",
    "action1 = algo.compute_single_action(obs[\"predator_1\"], policy_id=\"policy1\")\n",
    "action2 = algo.compute_single_action(obs[\"predator_2\"], policy_id=\"policy1\")\n",
    "action3 = algo.compute_single_action(obs[\"prey_3\"], policy_id=\"policy2\")\n",
    "action4 = algo.compute_single_action(obs[\"prey_4\"], policy_id=\"policy2\")\n",
    "action5 = algo.compute_single_action(obs[\"prey_5\"], policy_id=\"policy2\")\n",
    "\"\"\"\n",
    "print(\"action0\",action0)\n",
    "print(\"action1\",action1)\n",
    "print(\"action2\",action2)\n",
    "print(\"action3\",action3)\n",
    "print(\"action4\",action4)\n",
    "print(\"action5\",action5)\n",
    "\"\"\"\n",
    "algo.train()\n",
    "\n",
    "\n",
    "algo.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3012cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51381069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420d725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d34a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf344a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44715c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14869a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd09d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458ba7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19d65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUMBER IV\n",
    "from environments.predpreygrass_env import PredPreyGrassEnv\n",
    "from config.config_rllib import configuration\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.pre_checks.env import  check_env\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "env_config = {\n",
    "    \"no_done_at_end\": True,\n",
    "    \"rollout_fragment_length\": 1,\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"num_workers\": 0   \n",
    "    }\n",
    "\n",
    "check_env(PredPreyGrassEnv(configuration))\n",
    "\n",
    "def env_creator(configuration):\n",
    "    return PredPreyGrassEnv(configuration)  # return an env instance\n",
    "\n",
    "register_env(\"pred_prey_grass\", env_creator)\n",
    "\n",
    "policy1 = PolicySpec()\n",
    "policy2 = PolicySpec()\n",
    "\n",
    "policies = { \n",
    "    \"policy1\": policy1,\n",
    "    \"policy2\": policy2\n",
    "}\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id.lower().startswith(\"predator\"):\n",
    "        return \"policy1\"\n",
    "    if agent_id.lower().startswith(\"prey\"):\n",
    "        return \"policy2\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected agent ID: {agent_id}\")\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"pred_prey_grass\", env_config=env_config)\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(\n",
    "        create_env_on_local_worker=True, \n",
    "        rollout_fragment_length=1,\n",
    "        batch_mode=\"complete_episodes\",\n",
    "    )\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\n",
    "        \"fcnet_hiddens\" : [64, 64], \n",
    "        \"_disable_preprocessor_api\": False,\n",
    "        \"conv_filters\": [[32, [8, 8], 4], [64, [4, 4], 2], [512, [1, 1], 1]] # Copilot\n",
    "        }\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "algo = config.build()\n",
    "\n",
    "env = PredPreyGrassEnv(configuration=configuration)\n",
    "obs, _ = env.reset()\n",
    "\n",
    "#print(obs)\n",
    "\n",
    "action0 = algo.compute_single_action(obs[\"predator_0\"], policy_id=\"policy1\")\n",
    "action1 = algo.compute_single_action(obs[\"predator_1\"], policy_id=\"policy1\")\n",
    "action2 = algo.compute_single_action(obs[\"predator_2\"], policy_id=\"policy1\")\n",
    "action3 = algo.compute_single_action(obs[\"prey_3\"], policy_id=\"policy2\")\n",
    "action4 = algo.compute_single_action(obs[\"prey_4\"], policy_id=\"policy2\")\n",
    "action5 = algo.compute_single_action(obs[\"prey_5\"], policy_id=\"policy2\")\n",
    "print(\"action0\",action0)\n",
    "print(\"action1\",action1)\n",
    "print(\"action2\",action2)\n",
    "print(\"action3\",action3)\n",
    "print(\"action4\",action4)\n",
    "print(\"action5\",action5)\n",
    "\n",
    "algo.train()\n",
    "\n",
    "\n",
    "algo.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ab43b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a1e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783b7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f512d2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b2ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1f9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50f015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd61a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c516f037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c37c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27caa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define policies in dict with PolicySpec\n",
    "#add width and height parameters to the environment\n",
    "import ray\n",
    "from ray import train, tune\n",
    "\n",
    "from environments.predpreygrass_env import PredPreyGrassEnv\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from config.config_rllib import configuration\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "env = PredPreyGrassEnv(configuration=configuration)\n",
    "\n",
    "policy1 = PolicySpec(None,observation_space=env.observation_space, action_space=env.action_space)\n",
    "policy2 = PolicySpec(None,observation_space=env.observation_space, action_space=env.action_space)\n",
    "\n",
    "policies = { \n",
    "    \"policy1\": policy1,\n",
    "    \"policy2\": policy2\n",
    "}\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id[0:7] == \"predator\":\n",
    "        return \"policy1\"\n",
    "    elif agent_id[0:3] == \"prey\":\n",
    "        return \"policy2\"\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=PredPreyGrassEnv,env_config=configuration)\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\n",
    "        \"fcnet_hiddens\" : [64, 64], \n",
    "        \"_disable_preprocessor_api\": False,\n",
    "        \"conv_filters\": [[32, [8, 8], 4], [64, [4, 4], 2], [512, [1, 1], 1]] # Copilot\n",
    "        }\n",
    "    )\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 15},\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "tuner.fit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e06d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define policies in dict with PolicySpec\n",
    "#add width and height parameters to the environment\n",
    "#train the environment with the algo\n",
    "#use tune for a gridsearch\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "\n",
    "from environments.predpreygrass_env import PredPreyGrassEnv\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.utils.pre_checks.env import  check_env\n",
    "from config.config_rllib import configuration\n",
    "import time\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import time\n",
    "\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "                                                   \n",
    "def env_creator(configuration):\n",
    "    return PredPreyGrassEnv(configuration)  # return an env instance\n",
    "\n",
    "register_env(\"pred_prey_grass\", env_creator)\n",
    "\n",
    "policies = { \"policy1\": PolicySpec(), \"policy2\": PolicySpec() }\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id[0:7] == \"predator\":\n",
    "        return \"policy1\"\n",
    "    elif agent_id[0:3] == \"prey\":\n",
    "        return \"policy2\"\n",
    "\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"pred_prey_grass\")\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    #.training(model={\"fcnet_hiddens\" : [64, 64]},lr=tune.grid_search([0.01, 0.001, 0.0001]))\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]})\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 15},\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "tuner.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define policies in dict with PolicySpec\n",
    "#add width and height parameters to the environment\n",
    "#train the environment with the algo\n",
    "#use tune for a gridsearch\n",
    "#retrieving the checkpoint(s) of the trained agent\n",
    "\n",
    "import ray\n",
    "from ray import train, tune\n",
    "\n",
    "from multi_agent_env_ray_2_9_3 import MultiAgentArena\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.policy.policy import PolicySpec\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "import time\n",
    "\n",
    "MAX_WIDTH = 10\n",
    "MAX_HEIGHT = 10\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "                                                   \n",
    "def env_creator(env_config):\n",
    "    print(env_config)\n",
    "    return MultiAgentArena(config=env_config, width=MAX_WIDTH, height=MAX_HEIGHT)  # return an env instance\n",
    "register_env(\"multi_agent_arena\", env_creator)\n",
    "\n",
    "policies = { \"policy1\": PolicySpec(), \"policy2\": PolicySpec() }\n",
    "\n",
    "def policy_mapping_fn(agent_id, episode, worker, **kwargs):\n",
    "    if agent_id == \"agent1\":\n",
    "        return \"policy1\"\n",
    "    else:\n",
    "        return \"policy2\"\n",
    "\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=\"multi_agent_arena\")\n",
    "    .framework(\"torch\")\n",
    "    .rollouts(create_env_on_local_worker=True)\n",
    "    .debugging(seed=0,log_level=\"ERROR\")\n",
    "    .training(model={\"fcnet_hiddens\" : [64, 64]},lr=tune.grid_search([0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]))\n",
    "    .multi_agent(\n",
    "        policies=policies,\n",
    "        policy_mapping_fn=policy_mapping_fn\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# ``Tuner.fit()`` allows setting a custom log directory (other than ``~/ray-results``)\n",
    "tuner = ray.tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=config,\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 10},\n",
    "        checkpoint_config=train.CheckpointConfig(checkpoint_at_end=True),\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "\n",
    "# Get the best result based on a particular metric.\n",
    "best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "\n",
    "# Get the best checkpoint corresponding to the best result.\n",
    "best_checkpoint = best_result.checkpoint\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
